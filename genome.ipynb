{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip3 install -U requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "import pysam\n",
    "import seaborn as sns\n",
    "import umap\n",
    "import vcf\n",
    "from plotly.offline import init_notebook_mode, iplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from MulticoreTSNE import MulticoreTSNE as TSNE\n",
    "\n",
    "\n",
    "from cyvcf2 import VCF, Writer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "urllib.request.urlretrieve('ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/release/20130502/integrated_call_samples_v3.20130502.ALL.panel', 'file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vcf2df(vcf_fname):\n",
    "    \"\"\"Convert a subsetted vcf file to pandas DataFrame\n",
    "    and return sample-level population data\"\"\"\n",
    "    samples = 'ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/release/20130502/integrated_call_samples_v3.20130502.ALL.panel'\n",
    "    dfsamples = pd.read_csv(samples, sep='\\t')\n",
    "    dfsamples.set_index('sample', inplace=True)\n",
    "    dfsamples.drop(columns=['Unnamed: 4', 'Unnamed: 5'], inplace=True)\n",
    "\n",
    "    vcf_file = VCF(vcf_fname)\n",
    "    df = pd.DataFrame(index=vcf_file.samples)\n",
    "    for variant in vcf_file():\n",
    "        df[variant.ID] = variant.gt_types\n",
    "\n",
    "    df = df.join(dfsamples, how='outer')\n",
    "    df = df.drop(columns=['pop', 'super_pop', 'gender'])\n",
    "\n",
    "    return df, dfsamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vcf_fname = 'data/Kidd.55AISNP.1kG.vcf'\n",
    "df, dfsamples = vcf2df(vcf_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfsamples.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many samples and AISNPs?\n",
    "print(df.shape)\n",
    "\n",
    "# Are the two DataFrames the same length?\n",
    "print(df.shape[0] == dfsamples.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncols = len(df.columns)\n",
    "ohe = OneHotEncoder(categories=[range(4)] * ncols, sparse=False)\n",
    "\n",
    "X = ohe.fit_transform(df.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_dim(X, algorithm='PCA', n_components=4):\n",
    "    \"\"\"Reduce the dimensionality of the 55 AISNPs\n",
    "    :param X: One-hot encoded 1kG 55 AISNPs.\n",
    "    :type X: array\n",
    "    :param algorithm: The type of dimensionality reduction to perform. \n",
    "        One of {PCA, UMAP, TSNE}\n",
    "    :type algorithm: str \n",
    "    :param n_components: The number of components to return in X_red \n",
    "    :type n_components: int\n",
    "    \n",
    "    :returns: The transformed X[m, n] array, reduced to X[m, n_components] by algorithm.\n",
    "    \"\"\"\n",
    "    \n",
    "    if algorithm == 'PCA':\n",
    "        X_red = PCA(n_components=n_components).fit_transform(X)\n",
    "    elif algorithm == 'TSNE':\n",
    "        # TSNE, Barnes-Hut have dim <= 3\n",
    "        if n_components > 3:\n",
    "            print('The Barnes-Hut method requires the dimensionaility to be <= 3')\n",
    "            return None\n",
    "        else:\n",
    "            X_red = TSNE(n_components=n_components, n_jobs=4).fit_transform(X)\n",
    "    elif algorithm == 'UMAP':\n",
    "        X_red = umap.UMAP(n_components=n_components).fit_transform(X)\n",
    "    else:\n",
    "        return None\n",
    "    return X_red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_dim_df(X, algorithm='PCA', n_components=3):\n",
    "    \"\"\"Reduce the dimensionality of the 55 AISNPs\n",
    "    :param X: One-hot encoded 1kG 55 AISNPs.\n",
    "    :type X: array\n",
    "    :param X_me: Your one-hot encoded genotype array\n",
    "    :type X_me: array\n",
    "    :param algorithm: The type of dimensionality reduction to perform. \n",
    "        One of {PCA, UMAP, TSNE}\n",
    "    :type algorithm: str \n",
    "    :param n_components: The number of components to return in X_red \n",
    "    :type n_components: int\n",
    "    \n",
    "    :returns: The transformed X[m, n] array - reduced to X[m, n_components] by `algorithm`\n",
    "    \"\"\"\n",
    "    \n",
    "    if algorithm == 'PCA':\n",
    "        pca = PCA(n_components=n_components).fit(X)\n",
    "        X_red = pca.transform(X)\n",
    "#         X_red_me = pca.transform(X_me)\n",
    "        # merge your data into the same table as the reference data\n",
    "#         X_merged = np.vstack((X_red, X_red_me))\n",
    "        X_merged=X_red\n",
    "        df_red = pd.DataFrame(X_merged, \n",
    "                              columns=['component1', 'component2', 'component3'])\n",
    "    elif algorithm == 'TSNE':\n",
    "        # TSNE, Barnes-Hut have dim <= 3\n",
    "        if n_components > 3:\n",
    "            print('The Barnes-Hut method requires the dimensionaility to be <= 3')\n",
    "            return None\n",
    "        else:\n",
    "#             X_merged = np.vstack((X, X_me))\n",
    "            X_merged = X\n",
    "            X_red = mTSNE(n_components=n_components, n_jobs=4).fit_transform(X_merged)\n",
    "            df_red = pd.DataFrame(X_red, \n",
    "                                  columns=['component1', 'component2', 'component3'])\n",
    "    elif algorithm == 'UMAP':\n",
    "        umap_ = umap.UMAP(n_components=n_components).fit(X)\n",
    "        X_red = umap_.transform(X)\n",
    "#         X_red_me = umap_.transform(X_me) \n",
    "        # merge your data into the same table as the reference data\n",
    "#         X_merged = np.vstack((X_red, X_red_me))\n",
    "        X_merged=X_red\n",
    "        df_red = pd.DataFrame(X_merged, \n",
    "                              columns=['component1', 'component2', 'component3'])\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "    return df_red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_emb = reduce_dim(X, algorithm='PCA', n_components=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dim=reduce_dim_df(X, algorithm='PCA', n_components=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dim.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_dim = df_dim.join(dfsamples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_class(pop_level='pop'):\n",
    "    \"\"\"Encode the population lables for plotting.\"\"\"\n",
    "    le = LabelEncoder()\n",
    "    if pop_level == 'pop':\n",
    "        labels = le.fit_transform(dfsamples['pop'].values)\n",
    "    elif pop_level == 'super_pop':\n",
    "        labels = le.fit_transform(dfsamples['super_pop'].values)\n",
    "    else:\n",
    "        return None\n",
    "    return le, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pop_level can be either 'pop' or 'super_pop'\n",
    "le, labels = encode_class(pop_level='super_pop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_samples(X_emb, x_component=None, y_component=None):\n",
    "    \"\"\"\"\"\"\n",
    "    unique = np.unique(labels)\n",
    "    colors = [plt.cm.tab10_r(i/float(len(unique)-1)) for i in range(len(unique))]\n",
    "    assignments = [colors[i] for i in labels]\n",
    "\n",
    "    plt.figure(figsize=(10,10));\n",
    "    for (i,cla) in enumerate(set(labels)):\n",
    "        s = None\n",
    "        if le.inverse_transform([cla])[0] == 'me':\n",
    "            s=500\n",
    "        xc = [p for (j,p) in enumerate(X_emb[:, x_component-1]) if labels[j]==cla]\n",
    "        yc = [p for (j,p) in enumerate(X_emb[:, y_component-1]) if labels[j]==cla]\n",
    "        cols = [c for (j,c) in enumerate(assignments) if labels[j]==cla]\n",
    "        plt.scatter(xc, yc, s=s, c=cols, label=le.inverse_transform([cla])[0])\n",
    "    plt.legend();\n",
    "    plt.xlabel('Component {}'.format(x_component));\n",
    "    plt.ylabel('Component {}'.format(y_component));\n",
    "    plt.title('Projection of 1000 Genomes Samples\\ninto Lower Dimensional Space\\nUsing 55 AIMs from Kidd et al.');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy\n",
    "numpy.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "a = df_dim[[\"component1\",\"component2\",\"component3\"]].values\n",
    "numpy.savetxt(\"comp.csv\", a, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_samples(X_emb, x_component=1, y_component=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_figure_image(groups, layout):\n",
    "    data = []\n",
    "\n",
    "    for idx, val in groups:\n",
    "        if idx == 'me':\n",
    "            scatter = go.Scatter3d(\n",
    "            name=idx,\n",
    "            x=val.loc[:, 'component1'],\n",
    "            y=val.loc[:, 'component2'],\n",
    "            z=val.loc[:, 'component3'],\n",
    "            text=[idx for _ in range(val.loc[:, 'component1'].shape[0])],\n",
    "            textposition='middle right',\n",
    "            mode='markers',\n",
    "            marker=dict(\n",
    "                size=12,\n",
    "                symbol='diamond'\n",
    "                )\n",
    "            )\n",
    "        else:\n",
    "            scatter = go.Scatter3d(\n",
    "                name=idx,\n",
    "                x=val.loc[:, 'component1'],\n",
    "                y=val.loc[:, 'component2'],\n",
    "                z=val.loc[:, 'component3'],\n",
    "                text=[idx for _ in range(val.loc[:, 'component1'].shape[0])],\n",
    "                textposition='middle right',\n",
    "                mode='markers',\n",
    "                marker=dict(\n",
    "                    size=4,\n",
    "                    symbol='circle'\n",
    "                )\n",
    "            )\n",
    "        data.append(scatter)\n",
    "\n",
    "    figure = go.Figure(\n",
    "        data=data,\n",
    "        layout=layout\n",
    "    )\n",
    "    return figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layout = go.Layout(\n",
    "            margin=dict(l=0, r=0, b=0, t=0),\n",
    "            scene=dict(\n",
    "                xaxis=dict(\n",
    "                    title='Component 1',\n",
    "                    showgrid=True,\n",
    "                    zeroline=False,\n",
    "                    showticklabels=True\n",
    "                ),\n",
    "                yaxis=dict(\n",
    "                    title='Component 2',\n",
    "                    showgrid=True,\n",
    "                    zeroline=False,\n",
    "                    showticklabels=True\n",
    "                ),\n",
    "                zaxis=dict(\n",
    "                    title='Component 3',\n",
    "                    showgrid=True,\n",
    "                    zeroline=False,\n",
    "                    showticklabels=True\n",
    "                )\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dim"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
